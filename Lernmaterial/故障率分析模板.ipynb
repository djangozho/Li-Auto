{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine,Inspector\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reliability.Fitters as F\n",
    "import reliability.Distributions as D\n",
    "from datetime import datetime as dt\n",
    "from sqlalchemy import text\n",
    "today = dt.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'SimHei'  # 替换为你选择的字体\n",
    "today = dt.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据库连接引擎\n",
    "engine_dw = create_engine(\n",
    "    'mysql+pymysql://qs_pub_rw:QjxjUIyLw*3MxfHd@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dw',\n",
    "    pool_timeout=300)\n",
    "\n",
    "engine_dm = create_engine(\n",
    "    'mysql+pymysql://zlaq_dfq_rw_r:DFd2ITf9PQ7j$#k%@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dm',\n",
    "    pool_timeout=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 索赔单\n",
    "claims_sql = '''\n",
    "select * from\n",
    "(select claim_guarantee_code,vin,guarantee_amount,\n",
    "delivery_time,fault_time,\n",
    "driving_mileage,\n",
    "damage_material_code,damage_material_name,\n",
    "vehicle_category_code,LEFT(vehicle_category_code,3) as vehicle_cate_merge,\n",
    "usage_type_name\n",
    " from qso_dw.dwd_aftersale_claim_guarantee_order_df\n",
    "where 1=1 \n",
    "and guarantee_type != 30\n",
    "    and usage_type_name = '销售用车'\n",
    "    and damage_material_code in ('X01-79000093','X03-79000041','X01-79000011')\n",
    ") raw\n",
    "where 1=1 \n",
    "and vehicle_category_code in ('X03','X02','X01')\n",
    "'''\n",
    "#读取粘贴列 VIN+里程+交付日期+故障日期\n",
    "#claims_raw = pd.read_clipboard()\n",
    "\n",
    "claims_raw = pd.read_sql(text(claims_sql), engine_dw)\n",
    "\n",
    "\n",
    "\n",
    "## 输出索赔单\n",
    "#out_claims = pd.DataFrame(claims_raw)\n",
    "#out_claims.to_clipboard(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Could not reflect: requested table(s) not available in Engine(mysql+pymysql://zlaq_dfq_rw_r:***@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dm): (\nselect vin,total_odometer from qso_dm.dm_vom_drive_total_sum_df\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m mils_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mselect vin,total_odometer from qso_dm.dm_vom_drive_total_sum_df\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# dm_vom_adas_total_odometer  \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# dm_vom_drive_total_sum_df\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mils_raw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmils_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_dm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\zhoufeng7\\Python3\\Lib\\site-packages\\pandas\\io\\sql.py:724\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    721\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_table_name:\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    735\u001b[0m         sql,\n\u001b[0;32m    736\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    742\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    743\u001b[0m     )\n",
      "File \u001b[1;32md:\\zhoufeng7\\Python3\\Lib\\site-packages\\pandas\\io\\sql.py:1725\u001b[0m, in \u001b[0;36mSQLDatabase.read_table\u001b[1;34m(self, table_name, index_col, coerce_float, parse_dates, columns, schema, chunksize, dtype_backend)\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_table\u001b[39m(\n\u001b[0;32m   1663\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1664\u001b[0m     table_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1671\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1672\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[38;5;124;03m    Read SQL database table into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \n\u001b[0;32m   1724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreflect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviews\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1726\u001b[0m     table \u001b[38;5;241m=\u001b[39m SQLTable(table_name, \u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39mindex_col, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\zhoufeng7\\Python3\\Lib\\site-packages\\sqlalchemy\\sql\\schema.py:5817\u001b[0m, in \u001b[0;36mMetaData.reflect\u001b[1;34m(self, bind, schema, views, only, extend_existing, autoload_replace, resolve_fks, **dialect_kwargs)\u001b[0m\n\u001b[0;32m   5815\u001b[0m         s \u001b[38;5;241m=\u001b[39m schema \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m schema \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m schema) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5816\u001b[0m         missing_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing)\n\u001b[1;32m-> 5817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mInvalidRequestError(\n\u001b[0;32m   5818\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not reflect: requested table(s) not available \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5819\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbind\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5820\u001b[0m         )\n\u001b[0;32m   5821\u001b[0m     load \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   5822\u001b[0m         name\n\u001b[0;32m   5823\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m only\n\u001b[0;32m   5824\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m extend_existing \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m current\n\u001b[0;32m   5825\u001b[0m     ]\n\u001b[0;32m   5826\u001b[0m \u001b[38;5;66;03m# pass the available tables so the inspector can\u001b[39;00m\n\u001b[0;32m   5827\u001b[0m \u001b[38;5;66;03m# choose to ignore the filter_names\u001b[39;00m\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Could not reflect: requested table(s) not available in Engine(mysql+pymysql://zlaq_dfq_rw_r:***@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dm): (\nselect vin,total_odometer from qso_dm.dm_vom_drive_total_sum_df\n)"
     ]
    }
   ],
   "source": [
    "###里程\n",
    "mils_query = '''\n",
    "select vin,total_odometer from qso_dm.dm_vom_drive_total_sum_df\n",
    "'''\n",
    "# dm_vom_adas_total_odometer  \n",
    "# dm_vom_drive_total_sum_df\n",
    "\n",
    "mils_raw = pd.read_sql(mils_query, engine_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Could not reflect: requested table(s) not available in Engine(mysql+pymysql://zlaq_dfq_rw_r:***@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dm): (\nselect vin,vehicle_series_category_code,vehicle_model_name,factory_name,year_size,\nleft(actual_product_finish_time,10) as product_date, left(product_delivery_time,10) as delivery_date\nfrom qso_dim.dim_pro_prod_vehicle_base_info_df \nwhere 1=1 \nand vehicle_series_category_code = 'X04'\n-- and left(vehicle_series_category_code,1)  = 'M'\nand product_delivery_time is not null\n-- and actual_product_finish_time >= '2023-10-01 00:00:00'\n-- and actual_product_finish_time <= '2021-07-01 00:59:59'\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m###车辆\u001b[39;00m\n\u001b[0;32m      2\u001b[0m vehicle_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mselect vin,vehicle_series_category_code,vehicle_model_name,factory_name,year_size,\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mleft(actual_product_finish_time,10) as product_date, left(product_delivery_time,10) as delivery_date\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m-- and actual_product_finish_time <= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-07-01 00:59:59\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 13\u001b[0m vehicle_raw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvehicle_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_dm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(claims_raw))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mils_raw))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\sql.py:724\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    721\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_table_name:\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    735\u001b[0m         sql,\n\u001b[0;32m    736\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    742\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    743\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\sql.py:1725\u001b[0m, in \u001b[0;36mSQLDatabase.read_table\u001b[1;34m(self, table_name, index_col, coerce_float, parse_dates, columns, schema, chunksize, dtype_backend)\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_table\u001b[39m(\n\u001b[0;32m   1663\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1664\u001b[0m     table_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1671\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1672\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[38;5;124;03m    Read SQL database table into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \n\u001b[0;32m   1724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreflect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviews\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1726\u001b[0m     table \u001b[38;5;241m=\u001b[39m SQLTable(table_name, \u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39mindex_col, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\sql\\schema.py:5849\u001b[0m, in \u001b[0;36mMetaData.reflect\u001b[1;34m(self, bind, schema, views, only, extend_existing, autoload_replace, resolve_fks, **dialect_kwargs)\u001b[0m\n\u001b[0;32m   5847\u001b[0m         s \u001b[38;5;241m=\u001b[39m schema \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m schema \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m schema) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5848\u001b[0m         missing_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing)\n\u001b[1;32m-> 5849\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mInvalidRequestError(\n\u001b[0;32m   5850\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not reflect: requested table(s) not available \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5851\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbind\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5852\u001b[0m         )\n\u001b[0;32m   5853\u001b[0m     load \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   5854\u001b[0m         name\n\u001b[0;32m   5855\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m only\n\u001b[0;32m   5856\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m extend_existing \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m current\n\u001b[0;32m   5857\u001b[0m     ]\n\u001b[0;32m   5858\u001b[0m \u001b[38;5;66;03m# pass the available tables so the inspector can\u001b[39;00m\n\u001b[0;32m   5859\u001b[0m \u001b[38;5;66;03m# choose to ignore the filter_names\u001b[39;00m\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Could not reflect: requested table(s) not available in Engine(mysql+pymysql://zlaq_dfq_rw_r:***@dip-starrocks-compute.inner.chj.cloud:9030/hive_catalog.qso_dm): (\nselect vin,vehicle_series_category_code,vehicle_model_name,factory_name,year_size,\nleft(actual_product_finish_time,10) as product_date, left(product_delivery_time,10) as delivery_date\nfrom qso_dim.dim_pro_prod_vehicle_base_info_df \nwhere 1=1 \nand vehicle_series_category_code = 'X04'\n-- and left(vehicle_series_category_code,1)  = 'M'\nand product_delivery_time is not null\n-- and actual_product_finish_time >= '2023-10-01 00:00:00'\n-- and actual_product_finish_time <= '2021-07-01 00:59:59'\n)"
     ]
    }
   ],
   "source": [
    "###车辆\n",
    "vehicle_query = '''\n",
    "select vin,vehicle_series_category_code,vehicle_model_name,factory_name,year_size,\n",
    "left(actual_product_finish_time,10) as product_date, left(product_delivery_time,10) as delivery_date\n",
    "from qso_dim.dim_pro_prod_vehicle_base_info_df \n",
    "where 1=1 \n",
    "and vehicle_series_category_code in ('X03','X02','X01')\n",
    "-- and left(vehicle_series_category_code,1)  = 'M'\n",
    "and product_delivery_time is not null\n",
    "and actual_product_finish_time >= '2023-03-01 00:00:00'\n",
    "and actual_product_finish_time <= '2023-03-31 00:59:59'\n",
    "'''\n",
    "vehicle_raw = pd.read_sql(vehicle_query, engine_dm)\n",
    "\n",
    "print(len(claims_raw))\n",
    "print(len(mils_raw))\n",
    "print(len(vehicle_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mils_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### 车辆信息处理\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# assert 3>4, \"Houston we've got a problem\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m claims \u001b[38;5;241m=\u001b[39m claims_raw\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 5\u001b[0m mils \u001b[38;5;241m=\u001b[39m \u001b[43mmils_raw\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      6\u001b[0m vehicle \u001b[38;5;241m=\u001b[39m vehicle_raw\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#vehicle = vehicle.merge(mils,on='vin')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#粘贴列信息对齐\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#claims['vin'] = claims['VIN']\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#claims['total_odometer'] = claims['行驶里程']\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#claims['fault_time'] = claims['故障日期']\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mils_raw' is not defined"
     ]
    }
   ],
   "source": [
    "### 车辆信息处理\n",
    "\n",
    "# assert 3>4, \"Houston we've got a problem\"\n",
    "claims = claims_raw.copy()\n",
    "mils = mils_raw.copy()\n",
    "vehicle = vehicle_raw.copy()\n",
    "\n",
    "#vehicle = vehicle.merge(mils,on='vin')\n",
    "\n",
    "#粘贴列信息对齐\n",
    "#claims['vin'] = claims['VIN']\n",
    "#claims['total_odometer'] = claims['行驶里程']\n",
    "#claims['fault_time'] = claims['故障日期']\n",
    "\n",
    "claims = claims.merge(vehicle[['vin','delivery_date','product_date']],how='left',on='vin')\n",
    "vehicle = vehicle.merge(mils,on='vin')\n",
    "vehicle['use_days'] = (pd.to_datetime('2025-02-08') - pd.to_datetime(vehicle['delivery_date'])).dt.days\n",
    "vehicle['use_days'] = vehicle['use_days'].apply( lambda x: x if x > 1 else 1)\n",
    "claims['use_days']= (pd.to_datetime(claims['fault_time']) - pd.to_datetime(claims['delivery_time'])).dt.days\n",
    "### 粘贴列\n",
    "#claims['use_days']= (pd.to_datetime(claims['fault_time']) - pd.to_datetime(claims['delivery_date'])).dt.days\n",
    "claims['use_days'] = claims['use_days'].apply( lambda x: x if x > 1 else 1)\n",
    "### 里程分析\n",
    "#claims['total_odometer'] = claims['driving_mileage']\n",
    "#assert 3>4, \"Houston we've got a problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 失效车与风险车处理\n",
    "\n",
    "#assert 3>4\n",
    "\n",
    "\n",
    "# ['vin_use', 'vehicle_series_category_code', 'vehicle_category_code', 'vehicle_model_name', 'ticket_create_time', 'product_date', 'delivery_date', 'year_size', 'retail_store_province_name',\n",
    "#        'total_travel_mileage', 'extracted_value', 'part_code', 'part_barcode', 'mil_1000', 'accum_total_mileage']\n",
    "\n",
    "# claims = claims.loc[claims['guarantee_type']==10]\n",
    "\n",
    "failure_data = claims.loc[claims.vin.isin(vehicle.vin)]\n",
    "failure_data['use_days'].hist(bins=20)\n",
    "failure_data.sort_values('use_days',inplace=True)\n",
    "failure_data.drop_duplicates('vin',keep='first',inplace=True)\n",
    "# .loc[claims['ad_platform_name']=='AD MAX']\n",
    "risk_data = vehicle\n",
    "\n",
    "#vehicle['use_days'].hist(bins=20)\n",
    "\n",
    "\n",
    "print(len(failure_data),len(risk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 按故障天数\n",
    "\n",
    "\n",
    "\n",
    "left_data = failure_data.loc[(failure_data['product_date']>'2024-08-01')&(\n",
    "                        failure_data['use_days']>30)]\n",
    "right_data= risk_data.loc[(risk_data['product_date']>'2024-08-01')\n",
    "                        &(~risk_data['vin'].isin(failure_data['vin']))]\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['use_days'].tolist(),\n",
    "    right_censored = right_data['use_days'].tolist(),\n",
    "    CI_type='reliability')\n",
    "# plt.title('断点后-里程')\n",
    "\n",
    "left_data = failure_data.loc[(failure_data['product_date']<='2024-08-01')&(\n",
    "                        failure_data['use_days']>30)]\n",
    "right_data= risk_data.loc[(risk_data['product_date']<='2024-08-01')\n",
    "                        &(~risk_data['vin'].isin(failure_data['vin']))]\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['use_days'].tolist(),\n",
    "    right_censored = right_data['use_days'].tolist(),\n",
    "    CI_type='reliability')\n",
    "plt.title('断点前后-天数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 故障率分析 \n",
    "\n",
    "\n",
    "new_rate = len(failure_data.loc[failure_data['use_days']<=30])/len(risk_data)\n",
    "\n",
    "# new_rate = 0\n",
    "out = pd.DataFrame()\n",
    "# out['total_odometer'] = [10000*i for i in range(1,11)]\n",
    "## 100000公里质保\n",
    "out['use_days'] = [30 *(i+1)for i in range(60)]\n",
    "## 60个月质保\n",
    "\n",
    "out['平均(%)'] = out['use_days'].apply(lambda x : (1 - output.distribution.SF(x))*100) +new_rate*100\n",
    "out['95%上限(%)']=  out['use_days'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[-1]*100) +new_rate*100\n",
    "out['95%下限(%)']=  out['use_days'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[0]*100) +new_rate*100\n",
    "\n",
    "out.to_clipboard(index=False)\n",
    "\n",
    "#miles = 100000\n",
    "usedays = 1800\n",
    "use = out.loc[out['use_days'] == usedays]\n",
    "\n",
    "rate_ = use.values.reshape(-1)[2:]\n",
    "num_ = len(risk_data) * rate_/100 \n",
    "print(f\"{usedays}天故障率在{min(rate_) :.4f}%到{max(rate_) :.4f}%之间，估计损失件在{min(num_) :.0f}到{max(num_) :.0f}之间。更高天数数据缺乏证据，仅作为参考。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 按里程分布\n",
    "\n",
    "#assert 3>4\n",
    "#claims = claims_raw.copy()\n",
    "#vehicle = vehicle_raw.copy()\n",
    "#mils = mils_raw.copy()\n",
    "\n",
    "#vehicle = vehicle.merge(mils_raw,on='vin')\n",
    "# ['vin_use', 'vehicle_series_category_code', 'vehicle_category_code', 'vehicle_model_name', 'ticket_create_time', 'product_date', 'delivery_date', 'year_size', 'retail_store_province_name',\n",
    "#        'total_travel_mileage', 'extracted_value', 'part_code', 'part_barcode', 'mil_1000', 'accum_total_mileage']\n",
    "\n",
    "# claims = claims.loc[claims['guarantee_type']==10]\n",
    "#claims['vin'] = claims['VIN']\n",
    "#claims = claims.merge(vehicle[['vin','delivery_date','product_date']],how='left',on='vin')\n",
    "\n",
    "claims['total_odometer'] = claims['driving_mileage']\n",
    "failure_data = claims.loc[claims.vin.isin(vehicle.vin)]\n",
    "failure_data['total_odometer'].hist(bins=20)\n",
    "failure_data.sort_values('total_odometer',inplace=True)\n",
    "failure_data.drop_duplicates('vin',keep='first',inplace=True)\n",
    "# .loc[claims['ad_platform_name']=='AD MAX']\n",
    "risk_data = vehicle\n",
    "\n",
    "#risk_data['total_odometer'].hist(bins=20)\n",
    "\n",
    "\n",
    "print(len(failure_data),len(risk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert 3>4, \"Houston we've got a problem\"\n",
    "#故障件预处理\n",
    "\n",
    "left_data = failure_data.loc[(failure_data['product_date']>'2021-01-01')&\n",
    "                       (failure_data['total_odometer']>2000)]\n",
    "right_data= risk_data.loc[(risk_data['product_date']>'2021-01-01')\n",
    "                        &(~risk_data['vin'].isin(failure_data['vin']))]\n",
    "\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['total_odometer'].tolist(),\n",
    "    right_censored = right_data['total_odometer'].tolist(),\n",
    "    CI_type='reliability')\n",
    "# plt.title('断点后-里程')\n",
    "\n",
    "\n",
    "left_data = failure_data.loc[(failure_data['product_date']<='2021-01-01')&\n",
    "                        (failure_data['total_odometer']>2000)]\n",
    "right_data= risk_data.loc[(risk_data['product_date']<='2021-01-101')\n",
    "                        &(~risk_data['vin'].isin(failure_data['vin']))]\n",
    "\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['total_odometer'].tolist(),\n",
    "    right_censored = right_data['total_odometer'].tolist(),\n",
    "    CI_type='reliability')\n",
    "plt.title('断点前后-里程')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_rate = 0\n",
    "out = pd.DataFrame()\n",
    "out['total_odometer'] = [10000*i for i in range(1,11)]\n",
    "# out['使用天数'] = [30 *(i+1)for i in range(96)]\n",
    "\n",
    "out['平均(%)'] = out['total_odometer'].apply(lambda x : (1 - output.distribution.SF(x))*100) +new_rate*100\n",
    "out['95%上限(%)']=  out['total_odometer'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[-1]*100) +new_rate*100\n",
    "out['95%下限(%)']=  out['total_odometer'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[0]*100) +new_rate*100\n",
    "\n",
    "out.to_clipboard(index=False)\n",
    "\n",
    "miles = 100000\n",
    "use = out.loc[out['total_odometer'] == miles]\n",
    "\n",
    "rate_ = use.values.reshape(-1)[2:]\n",
    "num_ = len(risk_data) * rate_/100 \n",
    "print(f\"{miles}公里故障率在{min(rate_) :.4f}%到{max(rate_) :.4f}%之间，估计损失件在{min(num_) :.0f}到{max(num_) :.0f}之间。更高里程数据缺乏证据，仅作为参考。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rate = 0\n",
    "out = pd.DataFrame()\n",
    "out['里程'] = [10000*i for i in range(1,16)]\n",
    "# out['使用天数'] = [30 *(i+1)for i in range(96)]\n",
    "\n",
    "out['平均(%)'] = out['里程'].apply(lambda x : (1 - output.distribution.SF(x))*100) +new_rate*100\n",
    "out['95%上限(%)']=  out['里程'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[-1]*100) +new_rate*100\n",
    "out['95%下限(%)']=  out['里程'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[0]*100) +new_rate*100\n",
    "\n",
    "\n",
    "new_rate = 0\n",
    "out = pd.DataFrame()\n",
    "out['use_days'] = [100*i for i in range(1,20)]\n",
    "# out['使用天数'] = [30 *(i+1)for i in range(96)]\n",
    "\n",
    "out['平均(%)'] = out['use_days'].apply(lambda x : (1 - output.distribution.SF(x))*100) +new_rate*100\n",
    "out['95%上限(%)']=  out['use_days'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[-1]*100) +new_rate*100\n",
    "out['95%下限(%)']=  out['use_days'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[0]*100) +new_rate*100\n",
    "\n",
    "\n",
    "left_data = claims.loc[(claims['product_date']>'2021-01-15')&(claims['use_days']>1000)]\n",
    "right_data= vehicle.loc[(vehicle['product_date']>'2021-01-15')\n",
    "                        &(~vehicle['vin'].isin(claims['vin']))]\n",
    "\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['use_days'].tolist(),\n",
    "    right_censored = right_data['use_days'].tolist(),\n",
    "    CI_type='reliability')\n",
    "plt.title('断点后-使用天数')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_data = claims.loc[(claims['product_date']<='2021-01-15')&(claims['use_days']>1000)]\n",
    "right_data= vehicle.loc[(vehicle['product_date']<='2021-01-15')\n",
    "                        &(~vehicle['vin'].isin(claims['vin']))]\n",
    "\n",
    "output = F.Fit_Weibull_2P(\n",
    "    left_data['use_days'].tolist(),\n",
    "    right_censored = right_data['use_days'].tolist(),\n",
    "    CI_type='reliability')\n",
    "plt.title('断点后-使用天数')\n",
    "\n",
    "\n",
    "\n",
    "new_rate = 0\n",
    "out = pd.DataFrame()\n",
    "out['使用天数'] = [200*i for i in range(1,10)]\n",
    "# out['使用天数'] = [30 *(i+1)for i in range(96)]\n",
    "\n",
    "out['平均(%)'] = out['使用天数'].apply(lambda x : (1 - output.distribution.SF(x))*100) +new_rate*100\n",
    "out['95%上限(%)']=  out['使用天数'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[-1]*100) +new_rate*100\n",
    "out['95%下限(%)']=  out['使用天数'].apply(lambda x : output.distribution.CDF(CI_x=[x], CI=0.95)[0]*100) +new_rate*100\n",
    "\n",
    "\n",
    "5*365\n",
    "# 供应商保修 3年6万， 理想汽车5年10万"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
